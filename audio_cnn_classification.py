# -*- coding: utf-8 -*-
"""Audio-CNN-Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12zQpBU5YQGSM71BxKmXHxOS1oJHUsMfc
"""

import librosa
import matplotlib.pyplot as plt
import numpy as np
import kagglehub
import os
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import load_img, img_to_array

import gc

#get the path of audio-minist
path = kagglehub.dataset_download("sripaadsrinivasan/audio-mnist")
print("Path to dataset files:", path)

#to display the sound wave of serval MNIST audio examples
fig, ax = plt.subplots(1,6, figsize=(24, 5))
fig.suptitle('graphs of MNIST audio', fontsize=16)
for ii, letter in enumerate(['01' , '02', '03', '04', '05', '06']):
  dir = f'/kaggle/input/audio-mnist/data/{letter}'
  first_entry = os.listdir(dir)[0]
  full_path = os.path.join(dir, first_entry)
  y, sr = librosa.load(full_path)
  ax[ii].plot(y)

# Root directory for spectrograms
save_root_dir = "./spectrograms"

# Define training and validation root directories
train_root_dir = os.path.join(save_root_dir, "train")
valid_root_dir = os.path.join(save_root_dir, "valid")

# Create the main train and valid directories
os.makedirs(train_root_dir, exist_ok=True)
os.makedirs(valid_root_dir, exist_ok=True)

# Loop through each letter (subdirectory name)
for ii, letter in enumerate(['00','01','02','03','04','05','06','07','08','09']):
    # Create subdirectories for the current letter in train and valid directories
    train_dir = os.path.join(train_root_dir, letter)
    valid_dir = os.path.join(valid_root_dir, letter)
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(valid_dir, exist_ok=True)
for ii, letter in enumerate(['01','02','03','04']):
    # Process audio files in the current directory
    dir = f'/kaggle/input/audio-mnist/data/{letter}'
    file_list = os.listdir(dir)  # List of all files in the directory

    # Split files into training (80%) and validation (20%)
    train_files, val_files = train_test_split(file_list, test_size=0.2, random_state=42)

    # Process training files
    for i, file_name in enumerate(train_files):
        full_path = os.path.join(dir, file_name)
        y, sr = librosa.load(full_path, sr=16000)  # Downsample audio to 16 kHz
        stft_y = librosa.stft(y)
        S_db = librosa.amplitude_to_db(np.abs(stft_y), ref=np.max)
        spec_y = np.abs(S_db).astype(np.float32)  # Use float32 to reduce memory usage

        # Plot the spectrogram
        plt.figure(figsize=(15, 15))  # Smaller figure size
        librosa.display.specshow(spec_y, sr=sr, hop_length=512, y_axis="log", x_axis=None)
        plt.axis('off')
        # Save training spectrogram
        match file_name[0]:
          case '0':
            train_dir = os.path.join(train_root_dir, '00')
          case '1':
            train_dir = os.path.join(train_root_dir, '01')
          case '2':
            train_dir = os.path.join(train_root_dir, '02')
          case '3':
            train_dir = os.path.join(train_root_dir, '03')
          case '4':
            train_dir = os.path.join(train_root_dir, '04')
          case '5':
            train_dir = os.path.join(train_root_dir, '05')
          case '6':
            train_dir = os.path.join(train_root_dir, '06')
          case '7':
            train_dir = os.path.join(train_root_dir, '07')
          case '8':
            train_dir = os.path.join(train_root_dir, '08')
          case '9':
            train_dir = os.path.join(train_root_dir, '09')
        #save_path = os.path.join(train_dir, f'{file_name[0:3]}.png')
        save_path = os.path.join(train_dir, f'{file_name[:-4]}.png')
        #print(file_name, save_path)
        plt.savefig(save_path, bbox_inches="tight")  # Save without padding
        plt.close()
        gc.collect()  # Free memory

    # Process validation files
    for i, file_name in enumerate(val_files):
        full_path = os.path.join(dir, file_name)
        y, sr = librosa.load(full_path, sr=16000)
        stft_y = librosa.stft(y)
        S_db = librosa.amplitude_to_db(np.abs(stft_y), ref=np.max)
        spec_y = np.abs(S_db).astype(np.float32)

        # Plot the spectrogram
        plt.figure(figsize=(15, 15))
        librosa.display.specshow(spec_y, sr=sr, hop_length=512, y_axis="log", x_axis=None)
        plt.axis('off')

        # Save validation spectrogram
        match file_name[0]:
          case '0':
            valid_dir = os.path.join(valid_root_dir, '00')
          case '1':
            valid_dir = os.path.join(valid_root_dir, '01')
          case '2':
            valid_dir = os.path.join(valid_root_dir, '02')
          case '3':
            valid_dir = os.path.join(valid_root_dir, '03')
          case '4':
            valid_dir = os.path.join(valid_root_dir, '04')
          case '5':
            valid_dir = os.path.join(valid_root_dir, '05')
          case '6':
            valid_dir = os.path.join(valid_root_dir, '06')
          case '7':
            valid_dir = os.path.join(valid_root_dir, '07')
          case '8':
            valid_dir = os.path.join(valid_root_dir, '08')
          case '9':
            valid_dir = os.path.join(valid_root_dir, '09')
        #save_path = os.path.join(valid_dir, f'{file_name[0:3]}.png')
        save_path = os.path.join(valid_dir, f'{file_name[:-4]}.png')
        #print(file_name, save_path)
        plt.savefig(save_path, bbox_inches="tight")
        plt.close()
        gc.collect()

!rm -rf /content/spectrograms

train_dir = '/content/spectrograms/train'
validation_dataset = '/content/spectrograms/valid'

train_dataset = tf.keras.utils.image_dataset_from_directory(
 train_dir,
 image_size=(150, 150),
 batch_size=20,
 label_mode='categorical')

validation_dataset = tf.keras.utils.image_dataset_from_directory(
    directory=validation_dataset,
    batch_size=32,
    image_size=(150,150),
		label_mode='categorical',
    )

model = tf.keras.models.Sequential([
 tf.keras.Input(shape=(150, 150, 3)),
 tf.keras.layers.Rescaling(1./128),
 tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),
 tf.keras.layers.MaxPooling2D(2, 2),
 tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
 tf.keras.layers.MaxPooling2D(2, 2),
 tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
 tf.keras.layers.MaxPooling2D(2, 2),
 tf.keras.layers.Flatten(),
 tf.keras.layers.Dense(512, activation='relu'),
 tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(loss='categorical_crossentropy',
 optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),
 metrics=['accuracy'])

class MyCallback(tf.keras.callbacks.Callback):
 def on_epoch_end(self, epoch, logs=None):
  if logs['accuracy']>=0.99:
    self.model.stop_training = True

history = model.fit(train_dataset,
           epochs=15,
           validation_data=validation_dataset,
            callbacks=[MyCallback()])

# Get training and validation accuracies
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

# Get number of epochs
epochs = range(len(acc))

fig, ax = plt.subplots(1, 2, figsize=(10, 5))
fig.suptitle('Training and validation accuracy')

for i, (data, label) in enumerate(zip([(acc, val_acc), (loss, val_loss)], ["Accuracy", "Loss"])):
    ax[i].plot(epochs, data[0], 'r', label="Training " + label)
    ax[i].plot(epochs, data[1], 'b', label="Validation " + label)
    ax[i].legend()
    ax[i].set_xlabel('epochs')

plt.show()

validation_dir = "./spectrograms/valid"

# Function to preprocess and predict a single image
def predict_image(image_path, model, class_names):
    img = load_img(image_path, target_size=(150, 150))  # Load and resize image
    img_array = img_to_array(img)  # Convert image to numpy array
    img_array = tf.expand_dims(img_array, 0)  # Add batch dimension

    predictions = model.predict(img_array)  # Predict using the model
    predicted_class = np.argmax(predictions, axis=1)[0]  # Get predicted class
    confidence = np.max(predictions)  # Get confidence score

    return class_names[predicted_class], confidence

# Get class names from the validation dataset
class_names = validation_dataset.class_names

# Iterate through each subfolder in the validation directory
for class_folder in os.listdir(validation_dir):
    class_folder_path = os.path.join(validation_dir, class_folder)
    if os.path.isdir(class_folder_path):
        print(f"Processing class: {class_folder}")
        for image_file in os.listdir(class_folder_path):
            image_path = os.path.join(class_folder_path, image_file)
            predicted_label, confidence = predict_image(image_path, model, class_names)
            print(f"Image: {image_file}, Predicted: {predicted_label}, Confidence: {confidence:.2f}")